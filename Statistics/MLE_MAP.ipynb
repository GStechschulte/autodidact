{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation\n",
    "\n",
    "MLE is a widely used method for estimating probabilities from data. Namely, MLE is a method of estimating the parameters of a probability distribution by maximizing a likelihood function, so that under the assumed statistical model (parameterized) the observed data is most probable.\n",
    "\n",
    "Likelihood function: $L(\\theta | D)$\n",
    "\n",
    "You **maximize** the likelihood function such that, which $\\theta$ gives you the highest probability of observing the data\n",
    "\n",
    "$\\theta$$ = $$argmax_\\theta P(D; \\theta)$\n",
    " - Select the parameter that returns the highest probability of observing the data\n",
    "\n",
    "MLE = Maximizing $P(Y | x, \\theta) = \\prod_{i=1}^N(y_i | x_i, \\theta)$\n",
    "   - If we choose parameter $\\theta$, how likely is it that each particular $x_i$ gives rise to label $y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1 - Using Linear Algebra\n",
    "\n",
    "In order to find the parameters $\\theta$, it is kind of like reverse engineering. \n",
    "\n",
    "$\\underbrace{\\begin{pmatrix} -3 \\\\ -1 \\\\ 0 \\\\ 1 \\\\ 3 \\end{pmatrix}}_{\\mathbf{\\vec{x}}}$ *\n",
    "$\\underbrace{\\begin{pmatrix}  w \\end{pmatrix}}_{\\mathbf{\\vec{\\vec{w}}}}$ =\n",
    "$\\underbrace{\\begin{pmatrix} -1.2 \\\\ -0.7 \\\\ 0.14 \\\\ 0.67 \\\\ 1.67 \\end{pmatrix}}_{\\mathbf{\\vec{y}}}$\n",
    "\n",
    "What parameter $w$ when multiplied by $\\vec{x}$ lands on $\\vec{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training set\n",
    "X = np.array([-3, -1, 0, 1, 3]).reshape(-1,1) # 5x1 vector, N=5, D=1\n",
    "y = np.array([-1.2, -0.7, 0.14, 0.67, 1.67]).reshape(-1,1) # 5x1 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_likeli_est(X, y):\n",
    "    #N, D = X.shape[0], X.shape[1]\n",
    "    theta = np.linalg.solve(X.T @ X, X.T @ y)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.499]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_likeli_est(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Posterior Estimation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
